# ğŸ™ï¸ VoiceMorphAI â€” Diffusion-Based Voice Conversion ğŸµ

Transform *any voice* into a new style using cutting-edge **AudioLDM2 diffusion models**.  
VoiceMorphAI combines generative AI, deep learning, and audio synthesis to convert speech while preserving natural tone and emotion.

---

## ğŸš€ Demo

**Try it live (no login needed):**  
ğŸŒ Gradio link : https://33033413572f1d0fc5.gradio.live

<img width="1919" height="681" alt="Screenshot 2025-11-04 192402" src="https://github.com/user-attachments/assets/99a50481-c707-422e-aa70-8818dbfe300f" />



---

## ğŸ¨ Interface Preview

Below is a live demo snapshot of **VoiceMorphAI**, showing the clean Gradio-based user interface:

![VoiceMorphAI Demo Interface](6a53d1a4-df3a-4cef-8539-b2adcd5fed7c.png)

> ğŸ¤ Upload a `.wav` sample, describe a new voice style (e.g., â€œcalm robotic femaleâ€), and generate your transformed output using diffusion models.

---

## ğŸ§  Project Overview

**VoiceMorphAI** performs **text-guided voice transformation** using the **AudioLDM2 Large** model â€” an open-access diffusion model for audio generation.  
Users can upload a voice recording and describe a new style (e.g., _â€œrobotic whisperâ€_ or _â€œenergetic podcast hostâ€_) to synthesize a new version of the same speech.

### ğŸ”Š Key Features
- ğŸ§ **Voice-to-Voice Transformation** â€“ Converts uploaded voice to any target style.
- ğŸ¨ **Spectrogram Visualization** â€“ See the generated audioâ€™s frequency energy map.
- ğŸ” **Side-by-Side Comparison** â€“ Listen to *original vs generated* voices.
- ğŸ’¾ **Download Option** â€“ Save the generated voice instantly.
- â˜ï¸ **Fully Public** â€“ No API key or Hugging Face token required.

---

## âš™ï¸ Tech Stack

| Category | Tools / Frameworks |
|-----------|--------------------|
| ML Model | ğŸ§© AudioLDM2 (Diffusion-based audio generation) |
| Libraries | PyTorch Â· Diffusers Â· Transformers Â· Gradio Â· Librosa Â· SoundFile |
| Visualization | Matplotlib Â· Librosa.display |
| UI / Deployment | Gradio Blocks with public sharing |
| Environment | Google Colab / Python 3.10 |

---

## ğŸ§© Architecture

Input Voice (.wav)
      â”‚
      â–¼
Audio Preprocessing â”€â”€â”€â–º Diffusion Model (AudioLDM2)
      â”‚                           â”‚
      â–¼                           â–¼
Spectrogram                 Generated Audio
      â”‚                           â”‚
      â–¼                           â–¼
Visualization          Gradio Output + Download

---

## ğŸ“‚ Folder Structure

VoiceMorphAI/
â”‚
â”œâ”€â”€ VoiceMorphAI.ipynb        # Main Colab notebook
â”œâ”€â”€ README.md                 # Project overview & documentation
â”œâ”€â”€ requirements.txt          # Dependencies
â””â”€â”€ converted.wav             # Sample generated output (created after running)

---

## ğŸ”§ Installation & Usage

# Clone this repository

# Install dependencies
pip install -r requirements.txt

# Run in Colab or Jupyter
python VoiceMorphAI.ipynb

Or simply open it on Colab (recommended):  
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/dilipgou/VoiceMorphAI/blob/main/VoiceMorphAI.ipynb)

---

## ğŸ¯ Future Improvements

- Add voice cloning using speaker embeddings
- Train fine-tuned models for emotion-based conversion (RAVDESS dataset)
- Integrate with Hugging Face Spaces for permanent hosting
- Add waveform visualization alongside spectrogram

---

## ğŸ§‘â€ğŸ’» Author

**ğŸ‘‹ Dilip N**  
ğŸ’¼ Passionate about ML, Audio AI, and Generative Systems  


---

## ğŸª¶ License

MIT License Â© 2025 â€“ Dilip N
Feel free to use, modify, and share this project for learning and research.

